# Cyberbullying-Forecasting-Project
![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.8%2B-orange)
![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![License](https://img.shields.io/badge/License-MIT-green)

An AI-powered system to detect and predict cyberbullying in social media text using advanced NLP and machine learning techniques.

## Key Features âœ¨
- ğŸš© Real-time classification of toxic content (hate speech, threats, harassment)
- ğŸ” Context-aware analysis using BERT and LSTM models
- ğŸ“Š Sentiment and toxicity probability scoring
- âš¡ Scalable API for social media platforms
- ğŸ“ˆ Dashboard for moderation analytics

## Technology Stack ğŸ› ï¸
| Component            | Technologies Used                          |
|----------------------|--------------------------------------------|
| **Core NLP**         | BERT, RoBERTa, LSTM                        |
| **Text Processing**  | NLTK, SpaCy, HuggingFace Transformers      |
| **Backend**          | FastAPI, Flask                             |
| **Deployment**       | AWS Lambda, Docker                         |
| **Data Pipeline**    | Twitter/Reddit APIs, Pandas, PySpark       |

## Installation ğŸ“¦
```bash
git clone https://github.com/yourusername/cyberbullying-detection.git
cd cyberbullying-detection
pip install -r requirements.txt
python -m spacy download en_core_web_lg

Project Structure ğŸ“‚
.
â”œâ”€â”€ api/                  # FastAPI endpoints
â”œâ”€â”€ data/                 # Sample datasets
â”œâ”€â”€ models/               # Saved model weights
â”œâ”€â”€ notebooks/            # Jupyter notebooks for EDA
â”œâ”€â”€ preprocessing/        # Text cleaning scripts
â”œâ”€â”€ training/             # Model training scripts
â””â”€â”€ evaluation/           # Performance metrics

Results ğŸ“Š
Model	Accuracy	Precision	Recall
BERT-base	92.1%	89.5%	93.2%
LSTM	88.3%	85.1%	89.7%
SVM (baseline)	82.4%	79.8%	83.1%
